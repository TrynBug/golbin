{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 5-1 모의자료 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, models, regularizers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=50\n",
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 128\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    " \n",
    "    #normalize \n",
    "    mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "    std = np.std(x_train,axis=(0,1,2,3))\n",
    "    x_train = (x_train-mean)/(std+1e-7)\n",
    "    x_test = (x_test-mean)/(std+1e-7)\n",
    " \n",
    "    y_train =  tf.keras.utils.to_categorical(y_train,NUM_CLASSES)\n",
    "    y_test =  tf.keras.utils.to_categorical(y_test,NUM_CLASSES)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train, x_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from libs.connections import linear\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true images\n",
    "A=np.array([[0,0,0,0,0,0], [0,1,0,0,0,0],[0,1,1,0,0,0],[0,1,0,1,0,0],[0,1,0,0,1,0],[0,0,0,0,0,0]])\n",
    "B=np.array([[0,0,0,0,0,0], [0,0,0,0,1,0],[0,0,0,0,1,0],[0,0,0,0,1,0],[0,1,1,1,1,0],[0,0,0,0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 생성 \n",
    "trainX=np.zeros((20,36))\n",
    "for i in range(10):\n",
    "    trainX[i,:]=A.reshape(1,6*6)\n",
    "    trainX[i+10,:]=B.reshape(1,6*6)\n",
    "train_x=trainX.reshape(720,1)\n",
    "noise=np.random.choice(np.arange(2), 720, replace=True,p=[0.9,0.1])\n",
    "v=np.where(noise>0)\n",
    "train_x[v]=np.abs(train_x[v]-1)\n",
    "trainX=train_x.reshape(20,36)\n",
    "train_y=np.concatenate((np.ones((10,1)),np.zeros((10,1))),axis=0)\n",
    "train_y=np.array(train_y, np.int64)\n",
    "trainY = np_utils.to_categorical(train_y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 36)\n",
      "(20, 2)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(trainX).shape)\n",
    "print(np.array(trainY).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(trainX[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(trainY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 훈련 데이터 이미지\n",
    "f,axes =plt.subplots(figsize=(7,7), nrows=2, ncols=4, sharey=True, sharex=True)\n",
    "for ii in range(8):\n",
    "    plt.subplot(2,4,ii+1); \n",
    "    if ii<4: \n",
    "         if ii==0: plt.imshow(A,cmap='gray', interpolation='none')\n",
    "         else: plt.imshow(trainX[ii,:].reshape(6,6),cmap='gray', interpolation='none')\n",
    "    else: \n",
    "        if ii==4: plt.imshow(B,cmap='gray', interpolation='none')\n",
    "        else: plt.imshow(trainX[ii+5,:].reshape(6,6),cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.01; epochs=20\n",
    "#X=tf.placeholder(tf.float32,[None,36])\n",
    "#X_img=tf.reshape(X,[-1,6,6,1]) \n",
    "#Y=tf.placeholder(tf.float32,[None,2])\n",
    "trainX = trainX.reshape([-1,6,6,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 6, 6, 1)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# 합성곱에 사용하는 필터 크기와 개수, 보폭 지정\n",
    "#K1=tf.Variable(tf.random_normal([4,4,1,4],stddev=0.01))\n",
    "#a1=tf.nn.conv2d(X_img, K1, strides=[1,1,1,1], padding='VALID')\n",
    "# 활성화함수 지정 \n",
    "#a1=tf.nn.relu(a1)\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(filters=4, kernel_size=(5,5), strides=1, input_shape=(6,6,1), padding='valid', activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치정규화 \n",
    "#a1=tf.layers.batch_normalization(a1, training=True)\n",
    "model.add(tf.keras.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 풀링의 종류와 크기, 보폭 지정 \n",
    "#h1=tf.nn.max_pool(a1,ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), padding='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성층의 마지막 부분을 1D로 변환\n",
    "#Flat=tf.reshape(h1,[-1,np.prod(h1.get_shape().as_list()[1:4])])\n",
    "model.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완전 연결 신경망의 은닉층의 구조 지정\n",
    "#W1=tf.get_variable(\"W1\",shape=[np.prod(h1.get_shape().as_list()[1:4]),10],initializer=tf.contrib.layers.xavier_initializer())\n",
    "#b1=tf.Variable(tf.random_normal([10]))\n",
    "#L1=tf.matmul(Flat, W1)+b1\n",
    "# 최종 출력을 위해 소프트맥스함수 지정\n",
    "#pred =linear(L1, 2, activation=tf.nn.softmax)\n",
    "model.add(tf.keras.layers.Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 2, 2, 4)           104       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 2, 2, 4)           16        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 1, 1, 4)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 130\n",
      "Trainable params: 122\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=Y))\n",
    "#optim=tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "#correct_predict=tf.equal(tf.argmax(pred,1), tf.argmax(Y,1))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20/20 [==============================] - 4s 188ms/sample - loss: 0.2052 - acc: 0.9500\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 0s 987us/sample - loss: 0.1257 - acc: 1.0000\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 0s 399us/sample - loss: 0.0836 - acc: 1.0000\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 0s 250us/sample - loss: 0.0617 - acc: 1.0000\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0497 - acc: 1.0000\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 0s 201us/sample - loss: 0.0417 - acc: 1.0000\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0352 - acc: 1.0000\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 0s 209us/sample - loss: 0.0300 - acc: 1.0000\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0257 - acc: 1.0000\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 0s 149us/sample - loss: 0.0222 - acc: 1.0000\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 0s 250us/sample - loss: 0.0195 - acc: 1.0000\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0174 - acc: 1.0000\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 0s 199us/sample - loss: 0.0156 - acc: 1.0000\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0141 - acc: 1.0000\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0128 - acc: 1.0000\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 0s 150us/sample - loss: 0.0116 - acc: 1.0000\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 0s 201us/sample - loss: 0.0106 - acc: 1.0000\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0096 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.0089 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 0s 200us/sample - loss: 0.0081 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2083aace288>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(trainX), axis=1) == np.argmax(trainY, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 5-2 MNIST 손글씨 숫자 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from libs.connections import linear \n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자료 입력\n",
    "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.mnist.load_data()\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 10)\n",
      "(10000, 28, 28)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 훈련 데이터 이미지\n",
    "f,axes =plt.subplots(figsize=(7,7), nrows=3, ncols=4, sharey=True, sharex=True)\n",
    "for ii in range(12):\n",
    "    plt.subplot(3,4,ii+1)\n",
    "    plt.imshow(X_train[ii].reshape(28,28),cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001; epochs=10; batch_size=100\n",
    "X_train = X_train.reshape((60000, 28, 28, 1))\n",
    "X_test = X_test.reshape((10000, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "# 첫 번째 합성곱층에 사용하는 필터 크기와 개수, 보폭 지정\n",
    "# 첫 번째 합성곱층의 활성화함수 지정 \n",
    "model.add(tf.keras.layers.Conv2D(filters=20, kernel_size=(5,5), strides=1, input_shape=X_train.shape[1:], padding='valid', activation='relu'))\n",
    "# 배치정규화 \n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "# 첫 번째 풀링층에 사용하는 풀링의 종류와 크기, 보폭 지정\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), padding='valid'))\n",
    "# 두 번째 합성곱층에 사용하는 필터 크기와 개수, 보폭 지정\n",
    "# 두 번째 합성곱층의 활성화함수 지정\n",
    "model.add(tf.keras.layers.Conv2D(filters=50, kernel_size=(5,5), strides=1, padding='valid', activation='relu'))\n",
    "# 배치정규화 \n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "# 두 번째 풀링층에 사용하는 풀링의 종류와 크기, 보폭 지정\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), padding='valid'))\n",
    "#두 번째 풀링층의 출력을 1D로 변환\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "#완전 연결 신경망의 은닉층의 구조 지정\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 24, 24, 20)        520       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 24, 24, 20)        80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 50)          25050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 50)          200       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                8010      \n",
      "=================================================================\n",
      "Total params: 33,860\n",
      "Trainable params: 33,720\n",
      "Non-trainable params: 140\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "log_dir = os.path.join(\"logs\",datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs\\\\20200713-131250'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\project\\\\python\\\\golbin\\\\DeepLearningWithTnesorFlow\\\\5'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.1250 - accuracy: 0.9620\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.0405 - accuracy: 0.9875\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.0259 - accuracy: 0.9917\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.0207 - accuracy: 0.9934\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.0143 - accuracy: 0.9954\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.0102 - accuracy: 0.9967\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.0099 - accuracy: 0.9967\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.0076 - accuracy: 0.9976\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.0082 - accuracy: 0.9969\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.0083 - accuracy: 0.9970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18866ec9b48>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99765"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 데이터의 예측 정확도\n",
    "sum(np.argmax(model.predict(X_train), axis=1) == np.argmax(Y_train, axis=1)) / 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9877"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 검정 데이터의 예측 정확도\n",
    "sum(np.argmax(model.predict(X_test), axis=1) == np.argmax(Y_test, axis=1)) / 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 8912."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#log_dir = 'D:\\\\project\\\\python\\\\golbin\\\\DeepLearningWithTnesorFlow\\\\5\\\\logs\\\\20200713-131250'\n",
    "#log_dir = 'D:/project/python/golbin/DeepLearningWithTnesorFlow/5/logs/20200713-130406'\n",
    "%tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 5-3 MNIST 손글씨 숫자 분류(ResNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import namedtuple\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자료 입력\n",
    "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.mnist.load_data()\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 10)\n",
      "(10000, 28, 28)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rate=0.001; epochs=10; batch_size=100\n",
    "X_train = X_train.reshape((60000, 28, 28, 1))\n",
    "X_test = X_test.reshape((10000, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000, 10)\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001; epochs=10; batch_size=100\n",
    "X_train = X_train.reshape((60000, 28, 28, 1))\n",
    "X_test = X_test.reshape((10000, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet 블록 구조(bottleneck 구조) \n",
    "LayerBlock = namedtuple('LayerBlock', ['num_repeats', 'num_filters', 'bottleneck_size'])\n",
    "blocks = [LayerBlock(3, 128, 32),LayerBlock(3, 256, 64),LayerBlock(3, 512, 128),\n",
    "          LayerBlock(3, 1024, 256)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LayerBlock(num_repeats=3, num_filters=128, bottleneck_size=32),\n",
       " LayerBlock(num_repeats=3, num_filters=256, bottleneck_size=64),\n",
       " LayerBlock(num_repeats=3, num_filters=512, bottleneck_size=128),\n",
       " LayerBlock(num_repeats=3, num_filters=1024, bottleneck_size=256)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks[0].num_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 28, 28, 1) inputs; Input(shape= (28, 28, 1) )\n",
      "(None, 14, 14, 64) net; Conv2D(filters=64, kernel_size=(7,7), strides=2, padding=same)\n",
      "(None, 7, 7, 64) net; MaxPool2D(pool_size=(3,3), strides=(2, 2), padding=same)\n",
      "(None, 7, 7, 128) net; Conv2D(128, kernel_size=(1,1), strides=1, padding=valid)\n",
      "0 0 (None, 7, 7, 128) net\n",
      "0 0 (None, 7, 7, 32) conv1; Conv2D(filters= 32 , kernel_size=(1,1), padding=valid, strides=1)\n",
      "0 0 (None, 7, 7, 32) conv2; Conv2D(filters= 32 , kernel_size=(3,3), padding=same, strides=1)\n",
      "0 0 (None, 7, 7, 128) conv3; Conv2D(filters= 128 , kernel_size=(1,1), padding=valid, strides=1)\n",
      "0 1 (None, 7, 7, 128) net\n",
      "0 1 (None, 7, 7, 32) conv1; Conv2D(filters= 32 , kernel_size=(1,1), padding=valid, strides=1)\n",
      "0 1 (None, 7, 7, 32) conv2; Conv2D(filters= 32 , kernel_size=(3,3), padding=same, strides=1)\n",
      "0 1 (None, 7, 7, 128) conv3; Conv2D(filters= 128 , kernel_size=(1,1), padding=valid, strides=1)\n",
      "0 2 (None, 7, 7, 128) net\n",
      "0 2 (None, 7, 7, 32) conv1; Conv2D(filters= 32 , kernel_size=(1,1), padding=valid, strides=1)\n",
      "0 2 (None, 7, 7, 32) conv2; Conv2D(filters= 32 , kernel_size=(3,3), padding=same, strides=1)\n",
      "0 2 (None, 7, 7, 128) conv3; Conv2D(filters= 128 , kernel_size=(1,1), padding=valid, strides=1)\n",
      "0 (None, 7, 7, 256) net; Conv2D(filters= 256 , kernel_size=(1,1), padding=same, strides=1)\n",
      "1 0 (None, 7, 7, 256) net\n",
      "1 0 (None, 7, 7, 64) conv1; Conv2D(filters= 64 , kernel_size=(1,1), padding=valid, strides=1)\n",
      "1 0 (None, 7, 7, 64) conv2; Conv2D(filters= 64 , kernel_size=(3,3), padding=same, strides=1)\n",
      "1 0 (None, 7, 7, 256) conv3; Conv2D(filters= 256 , kernel_size=(1,1), padding=valid, strides=1)\n",
      "1 1 (None, 7, 7, 256) net\n",
      "1 1 (None, 7, 7, 64) conv1; Conv2D(filters= 64 , kernel_size=(1,1), padding=valid, strides=1)\n",
      "1 1 (None, 7, 7, 64) conv2; Conv2D(filters= 64 , kernel_size=(3,3), padding=same, strides=1)\n",
      "1 1 (None, 7, 7, 256) conv3; Conv2D(filters= 256 , kernel_size=(1,1), padding=valid, strides=1)\n",
      "1 2 (None, 7, 7, 256) net\n",
      "1 2 (None, 7, 7, 64) conv1; Conv2D(filters= 64 , kernel_size=(1,1), padding=valid, strides=1)\n",
      "1 2 (None, 7, 7, 64) conv2; Conv2D(filters= 64 , kernel_size=(3,3), padding=same, strides=1)\n",
      "1 2 (None, 7, 7, 256) conv3; Conv2D(filters= 256 , kernel_size=(1,1), padding=valid, strides=1)\n",
      "1 (None, 7, 7, 512) net; Conv2D(filters= 512 , kernel_size=(1,1), padding=same, strides=1)\n",
      "2 0 (None, 7, 7, 512) net\n",
      "2 0 (None, 7, 7, 128) conv1; Conv2D(filters= 128 , kernel_size=(1,1), padding=valid, strides=1)\n",
      "2 0 (None, 7, 7, 128) conv2; Conv2D(filters= 128 , kernel_size=(3,3), padding=same, strides=1)\n",
      "2 0 (None, 7, 7, 512) conv3; Conv2D(filters= 512 , kernel_size=(1,1), padding=valid, strides=1)\n",
      "2 1 (None, 7, 7, 512) net\n",
      "2 1 (None, 7, 7, 128) conv1; Conv2D(filters= 128 , kernel_size=(1,1), padding=valid, strides=1)\n",
      "2 1 (None, 7, 7, 128) conv2; Conv2D(filters= 128 , kernel_size=(3,3), padding=same, strides=1)\n",
      "2 1 (None, 7, 7, 512) conv3; Conv2D(filters= 512 , kernel_size=(1,1), padding=valid, strides=1)\n",
      "2 2 (None, 7, 7, 512) net\n",
      "2 2 (None, 7, 7, 128) conv1; Conv2D(filters= 128 , kernel_size=(1,1), padding=valid, strides=1)\n",
      "2 2 (None, 7, 7, 128) conv2; Conv2D(filters= 128 , kernel_size=(3,3), padding=same, strides=1)\n",
      "2 2 (None, 7, 7, 512) conv3; Conv2D(filters= 512 , kernel_size=(1,1), padding=valid, strides=1)\n",
      "2 (None, 7, 7, 1024) net; Conv2D(filters= 1024 , kernel_size=(1,1), padding=same, strides=1)\n",
      "3 0 (None, 7, 7, 1024) net\n",
      "3 0 (None, 7, 7, 256) conv1; Conv2D(filters= 256 , kernel_size=(1,1), padding=valid, strides=1)\n",
      "3 0 (None, 7, 7, 256) conv2; Conv2D(filters= 256 , kernel_size=(3,3), padding=same, strides=1)\n",
      "3 0 (None, 7, 7, 1024) conv3; Conv2D(filters= 1024 , kernel_size=(1,1), padding=valid, strides=1)\n",
      "3 1 (None, 7, 7, 1024) net\n",
      "3 1 (None, 7, 7, 256) conv1; Conv2D(filters= 256 , kernel_size=(1,1), padding=valid, strides=1)\n",
      "3 1 (None, 7, 7, 256) conv2; Conv2D(filters= 256 , kernel_size=(3,3), padding=same, strides=1)\n",
      "3 1 (None, 7, 7, 1024) conv3; Conv2D(filters= 1024 , kernel_size=(1,1), padding=valid, strides=1)\n",
      "3 2 (None, 7, 7, 1024) net\n",
      "3 2 (None, 7, 7, 256) conv1; Conv2D(filters= 256 , kernel_size=(1,1), padding=valid, strides=1)\n",
      "3 2 (None, 7, 7, 256) conv2; Conv2D(filters= 256 , kernel_size=(3,3), padding=same, strides=1)\n",
      "3 2 (None, 7, 7, 1024) conv3; Conv2D(filters= 1024 , kernel_size=(1,1), padding=valid, strides=1)\n",
      "IndexError\n",
      "(None, 1, 1, 1024) net; AveragePooling2D(pool_size=( 1 , 1 ), strides=1, padding=valid)\n",
      "(None, 1024) Flat; Flatten()\n",
      "(None, 10) Y_pred; Dense(10, activation=softmax)\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=X_train.shape[1:])\n",
    "print(inputs.shape, 'inputs; Input(shape=',X_train.shape[1:],')')\n",
    "# 채널수 64의 합성곱 출력을 만들고 다운샘플링\n",
    "net = Conv2D(filters=64, kernel_size=(7,7), strides=2, padding='same', activation='relu', name='conv1')(inputs)\n",
    "print(net.shape, 'net; Conv2D(filters=64, kernel_size=(7,7), strides=2, padding=''same'')')\n",
    "\n",
    "net = MaxPool2D(pool_size=(3,3), strides=(2, 2), padding='same')(net)\n",
    "print(net.shape, 'net; MaxPool2D(pool_size=(3,3), strides=(2, 2), padding=''same'')')\n",
    "\n",
    "# ResNet 블록구조의 입력 생성 \n",
    "net = Conv2D(128, kernel_size=(1,1), strides=1, padding='valid', name='conv2')(net)\n",
    "print(net.shape, 'net; Conv2D(128, kernel_size=(1,1), strides=1, padding=''valid'')')\n",
    "\n",
    "# ResNet 블록 반복 \n",
    "for block_i, block in enumerate(blocks):\n",
    "    for repeat_i in range(block.num_repeats):\n",
    "        name = 'block_%d/repeat_%d' % (block_i, repeat_i)\n",
    "        print(block_i, repeat_i, net.shape, 'net')\n",
    "        conv1 = Conv2D(filters=block.bottleneck_size, \n",
    "                       kernel_size=(1,1), padding='valid', strides=1, \n",
    "                       activation='relu', name=name + '/conv_in')(net)\n",
    "        print(block_i, repeat_i, conv1.shape, 'conv1; Conv2D(filters=',block.bottleneck_size,', kernel_size=(1,1), padding=''valid'', strides=1)')\n",
    "\n",
    "        conv2 = Conv2D(filters=block.bottleneck_size,\n",
    "                       kernel_size=(3,3), padding='same', strides=1,\n",
    "                       activation='relu', name=name + '/conv_bottleneck')(conv1)\n",
    "        print(block_i, repeat_i, conv2.shape, 'conv2; Conv2D(filters=',block.bottleneck_size,', kernel_size=(3,3), padding=''same'', strides=1)')\n",
    "\n",
    "        conv3 = Conv2D(filters=block.num_filters,\n",
    "                       kernel_size=(1,1), padding='valid', strides=1,\n",
    "                       activation='relu', name=name + '/conv_out')(conv2)\n",
    "        print(block_i, repeat_i, conv3.shape, 'conv3; Conv2D(filters=',block.num_filters,', kernel_size=(1,1), padding=''valid'', strides=1)')\n",
    "        net = conv3 + net\n",
    "\n",
    "    try:\n",
    "        # upscale to the next block size\n",
    "        next_block = blocks[block_i + 1]\n",
    "        net = Conv2D(filters=next_block.num_filters,\n",
    "                     kernel_size=(1,1), padding='same', strides=1, use_bias=False,\n",
    "                     name='block_%d/conv_upscale' % block_i)(net)\n",
    "        print(block_i, net.shape, 'net; Conv2D(filters=', next_block.num_filters, ', kernel_size=(1,1), padding=''same'', strides=1)')\n",
    "    except IndexError:\n",
    "        print(\"IndexError\")\n",
    "        pass\n",
    "\n",
    "# 평균 풀링을 이용하여 블록 구조의 최종 출력의 차원 변환\n",
    "net = tf.keras.layers.AveragePooling2D(pool_size=(net.shape[1],net.shape[2]), strides=1, padding='valid')(net)\n",
    "print(net.shape, 'net; AveragePooling2D(pool_size=(',net.shape[1],',',net.shape[2],'), strides=1, padding=''valid'')')\n",
    "\n",
    "#ResNet 블록 구조의 최종 출력을 1D로 변환\n",
    "Flat=tf.keras.layers.Flatten()(net)\n",
    "print(Flat.shape, 'Flat; Flatten()')\n",
    "# 최종 출력을 위해 소프트맥스함수 지정\n",
    "Y_pred=tf.keras.layers.Dense(10, activation='softmax')(Flat)\n",
    "print(Y_pred.shape, 'Y_pred; Dense(10, activation=''softmax'')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 14, 14, 64)   3200        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 7, 7, 64)     0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 7, 7, 128)    8320        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_0/repeat_0/conv_in (Conv2 (None, 7, 7, 32)     4128        conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_0/repeat_0/conv_bottlenec (None, 7, 7, 32)     9248        block_0/repeat_0/conv_in[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_0/repeat_0/conv_out (Conv (None, 7, 7, 128)    4224        block_0/repeat_0/conv_bottleneck[\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add (TensorFlowOpLa [(None, 7, 7, 128)]  0           block_0/repeat_0/conv_out[0][0]  \n",
      "                                                                 conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_0/repeat_1/conv_in (Conv2 (None, 7, 7, 32)     4128        tf_op_layer_add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_0/repeat_1/conv_bottlenec (None, 7, 7, 32)     9248        block_0/repeat_1/conv_in[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_0/repeat_1/conv_out (Conv (None, 7, 7, 128)    4224        block_0/repeat_1/conv_bottleneck[\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_1 (TensorFlowOp [(None, 7, 7, 128)]  0           block_0/repeat_1/conv_out[0][0]  \n",
      "                                                                 tf_op_layer_add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_0/repeat_2/conv_in (Conv2 (None, 7, 7, 32)     4128        tf_op_layer_add_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_0/repeat_2/conv_bottlenec (None, 7, 7, 32)     9248        block_0/repeat_2/conv_in[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_0/repeat_2/conv_out (Conv (None, 7, 7, 128)    4224        block_0/repeat_2/conv_bottleneck[\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_2 (TensorFlowOp [(None, 7, 7, 128)]  0           block_0/repeat_2/conv_out[0][0]  \n",
      "                                                                 tf_op_layer_add_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_0/conv_upscale (Conv2D)   (None, 7, 7, 256)    32768       tf_op_layer_add_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1/repeat_0/conv_in (Conv2 (None, 7, 7, 64)     16448       block_0/conv_upscale[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1/repeat_0/conv_bottlenec (None, 7, 7, 64)     36928       block_1/repeat_0/conv_in[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1/repeat_0/conv_out (Conv (None, 7, 7, 256)    16640       block_1/repeat_0/conv_bottleneck[\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_3 (TensorFlowOp [(None, 7, 7, 256)]  0           block_1/repeat_0/conv_out[0][0]  \n",
      "                                                                 block_0/conv_upscale[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1/repeat_1/conv_in (Conv2 (None, 7, 7, 64)     16448       tf_op_layer_add_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1/repeat_1/conv_bottlenec (None, 7, 7, 64)     36928       block_1/repeat_1/conv_in[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1/repeat_1/conv_out (Conv (None, 7, 7, 256)    16640       block_1/repeat_1/conv_bottleneck[\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_4 (TensorFlowOp [(None, 7, 7, 256)]  0           block_1/repeat_1/conv_out[0][0]  \n",
      "                                                                 tf_op_layer_add_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1/repeat_2/conv_in (Conv2 (None, 7, 7, 64)     16448       tf_op_layer_add_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1/repeat_2/conv_bottlenec (None, 7, 7, 64)     36928       block_1/repeat_2/conv_in[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1/repeat_2/conv_out (Conv (None, 7, 7, 256)    16640       block_1/repeat_2/conv_bottleneck[\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_5 (TensorFlowOp [(None, 7, 7, 256)]  0           block_1/repeat_2/conv_out[0][0]  \n",
      "                                                                 tf_op_layer_add_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1/conv_upscale (Conv2D)   (None, 7, 7, 512)    131072      tf_op_layer_add_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2/repeat_0/conv_in (Conv2 (None, 7, 7, 128)    65664       block_1/conv_upscale[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2/repeat_0/conv_bottlenec (None, 7, 7, 128)    147584      block_2/repeat_0/conv_in[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_2/repeat_0/conv_out (Conv (None, 7, 7, 512)    66048       block_2/repeat_0/conv_bottleneck[\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_6 (TensorFlowOp [(None, 7, 7, 512)]  0           block_2/repeat_0/conv_out[0][0]  \n",
      "                                                                 block_1/conv_upscale[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2/repeat_1/conv_in (Conv2 (None, 7, 7, 128)    65664       tf_op_layer_add_6[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2/repeat_1/conv_bottlenec (None, 7, 7, 128)    147584      block_2/repeat_1/conv_in[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_2/repeat_1/conv_out (Conv (None, 7, 7, 512)    66048       block_2/repeat_1/conv_bottleneck[\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_7 (TensorFlowOp [(None, 7, 7, 512)]  0           block_2/repeat_1/conv_out[0][0]  \n",
      "                                                                 tf_op_layer_add_6[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2/repeat_2/conv_in (Conv2 (None, 7, 7, 128)    65664       tf_op_layer_add_7[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2/repeat_2/conv_bottlenec (None, 7, 7, 128)    147584      block_2/repeat_2/conv_in[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_2/repeat_2/conv_out (Conv (None, 7, 7, 512)    66048       block_2/repeat_2/conv_bottleneck[\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_8 (TensorFlowOp [(None, 7, 7, 512)]  0           block_2/repeat_2/conv_out[0][0]  \n",
      "                                                                 tf_op_layer_add_7[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2/conv_upscale (Conv2D)   (None, 7, 7, 1024)   524288      tf_op_layer_add_8[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3/repeat_0/conv_in (Conv2 (None, 7, 7, 256)    262400      block_2/conv_upscale[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3/repeat_0/conv_bottlenec (None, 7, 7, 256)    590080      block_3/repeat_0/conv_in[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_3/repeat_0/conv_out (Conv (None, 7, 7, 1024)   263168      block_3/repeat_0/conv_bottleneck[\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_9 (TensorFlowOp [(None, 7, 7, 1024)] 0           block_3/repeat_0/conv_out[0][0]  \n",
      "                                                                 block_2/conv_upscale[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3/repeat_1/conv_in (Conv2 (None, 7, 7, 256)    262400      tf_op_layer_add_9[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3/repeat_1/conv_bottlenec (None, 7, 7, 256)    590080      block_3/repeat_1/conv_in[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_3/repeat_1/conv_out (Conv (None, 7, 7, 1024)   263168      block_3/repeat_1/conv_bottleneck[\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_10 (TensorFlowO [(None, 7, 7, 1024)] 0           block_3/repeat_1/conv_out[0][0]  \n",
      "                                                                 tf_op_layer_add_9[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3/repeat_2/conv_in (Conv2 (None, 7, 7, 256)    262400      tf_op_layer_add_10[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3/repeat_2/conv_bottlenec (None, 7, 7, 256)    590080      block_3/repeat_2/conv_in[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_3/repeat_2/conv_out (Conv (None, 7, 7, 1024)   263168      block_3/repeat_2/conv_bottleneck[\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_11 (TensorFlowO [(None, 7, 7, 1024)] 0           block_3/repeat_2/conv_out[0][0]  \n",
      "                                                                 tf_op_layer_add_10[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 1, 1024)   0           tf_op_layer_add_11[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1024)         0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           10250       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,157,578\n",
      "Trainable params: 5,157,578\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs, Y_pred)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs\\\\20200713-131654'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 37s 622us/sample - loss: 1.4880 - accuracy: 0.8701\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 33s 552us/sample - loss: 0.0790 - accuracy: 0.9756\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 34s 566us/sample - loss: 0.0553 - accuracy: 0.9829\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 34s 563us/sample - loss: 0.0480 - accuracy: 0.9856\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 34s 561us/sample - loss: 0.0474 - accuracy: 0.9853\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 34s 560us/sample - loss: 0.0497 - accuracy: 0.9850\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 33s 555us/sample - loss: 0.0501 - accuracy: 0.9856\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 33s 553us/sample - loss: 0.0621 - accuracy: 0.9825\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 33s 553us/sample - loss: 0.0602 - accuracy: 0.9833\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 33s 556us/sample - loss: 0.0603 - accuracy: 0.9830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16d4b008d08>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9902833333333333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 데이터의 예측 정확도\n",
    "sum(np.argmax(model.predict(X_train), axis=1) == np.argmax(Y_train, axis=1)) / 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9856"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 검정 데이터의 예측 정확도\n",
    "sum(np.argmax(model.predict(X_test), axis=1) == np.argmax(Y_test, axis=1)) / 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 24388."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(tf.keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ResNet, self).__init__(**kwargs)\n",
    "        \n",
    "    def call(self, x):\n",
    "        return x\n",
    "    \n",
    "    def build_graph(self, input_shape): \n",
    "        input_shape_nobatch = input_shape[1:]\n",
    "        self.build(input_shape)\n",
    "        inputs = tf.keras.Input(shape=input_shape_nobatch)\n",
    "        \n",
    "        if not hasattr(self, 'call'):\n",
    "            raise AttributeError(\"User should define 'call' method in sub-class model!\")\n",
    "        \n",
    "        _ = self.call(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
