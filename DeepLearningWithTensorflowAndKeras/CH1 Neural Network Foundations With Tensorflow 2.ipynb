{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Further improving the simple net in TensorFlow with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10 # number of outputs = number of digits\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT = 0.2\n",
    "DROPOUT = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading MNIST dataset\n",
    "# Labels have one-hot representation\n",
    "mnist = keras.datasets.mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESHAPED = 784\n",
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Normalize inputs within [0, 1]\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot representations for labels\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "model = tf.keras.models.Sequential()\n",
    "# kernel_initializer 파라미터는 가중치의 초기값을 지정할 때 사용한다. 사용가능한 값은 아래와 같다\n",
    "# random_uniform : -0.05 to 0.05의 uniform dustribution 값으로 초기화\n",
    "# random_normal : 표준편차 0.05의 정규분포 값으로 초기화\n",
    "# zero : 0으로 초기화\n",
    "# 더 많은 정보는 https://www.tensorflow.org/api_docs/python/tf/keras/initializers\n",
    "model.add(keras.layers.Dense(N_HIDDEN, input_shape = (RESHAPED,), name='dense_layer', activation='relu', kernel_initializer='random_normal', kernel_regularizer=l2(0.01), activity_regularizer=l2(0.01)))\n",
    "model.add(keras.layers.Dropout(DROPOUT))\n",
    "model.add(keras.layers.Dense(N_HIDDEN, name='dense_layer_2', activation='relu'))\n",
    "model.add(keras.layers.Dropout(DROPOUT))\n",
    "model.add(keras.layers.Dense(NB_CLASSES, name='dense_layer_3', activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_layer (Dense)          (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer_2 (Dense)        (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer_3 (Dense)        (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "# 사용 가능한 objective function은 아래와 같다\n",
    "# MSE : mean squared error between predictions and the true values\n",
    "# binary_crossentropy : 바이너리 레이블 예측에 적합하다\n",
    "# categorical_crossentropy : 멀티클래스 로그 손실함수이다. 예측값의 분포와 실제 분포를 비교한다. 멀티클래스 레이블 예측에 적합하다. softmax activation과 함께 사용하는 것이 기본선택이다.\n",
    "# 더 많은 정보는 https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
    "# metrics 파라미터는 오직 모델을 평가하는데에 사용할 방법을 설정한다. 모델 학습에는 사용되지 않는다\n",
    "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 1s 28us/sample - loss: 4.3065 - accuracy: 0.4173 - val_loss: 3.5268 - val_accuracy: 0.7819\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 1s 16us/sample - loss: 3.2471 - accuracy: 0.7106 - val_loss: 2.7100 - val_accuracy: 0.8625\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 1s 16us/sample - loss: 2.6556 - accuracy: 0.7915 - val_loss: 2.2679 - val_accuracy: 0.8847\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 1s 16us/sample - loss: 2.2709 - accuracy: 0.8292 - val_loss: 1.9503 - val_accuracy: 0.8967\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 1.9721 - accuracy: 0.8498 - val_loss: 1.6972 - val_accuracy: 0.9068\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 1.7326 - accuracy: 0.8663 - val_loss: 1.4909 - val_accuracy: 0.9119\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 1.5319 - accuracy: 0.8766 - val_loss: 1.3171 - val_accuracy: 0.9177\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 1.3696 - accuracy: 0.8843 - val_loss: 1.1700 - val_accuracy: 0.9223\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 1s 18us/sample - loss: 1.2260 - accuracy: 0.8891 - val_loss: 1.0448 - val_accuracy: 0.9253\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 1.1037 - accuracy: 0.8947 - val_loss: 0.9379 - val_accuracy: 0.9269\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 1s 16us/sample - loss: 0.9990 - accuracy: 0.9004 - val_loss: 0.8458 - val_accuracy: 0.9296\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.9089 - accuracy: 0.9044 - val_loss: 0.7668 - val_accuracy: 0.9316\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 1s 18us/sample - loss: 0.8314 - accuracy: 0.9067 - val_loss: 0.6975 - val_accuracy: 0.9350\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 1s 18us/sample - loss: 0.7630 - accuracy: 0.9111 - val_loss: 0.6397 - val_accuracy: 0.9358\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.7089 - accuracy: 0.9115 - val_loss: 0.5894 - val_accuracy: 0.9369\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 1s 18us/sample - loss: 0.6573 - accuracy: 0.9154 - val_loss: 0.5424 - val_accuracy: 0.9408\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.6149 - accuracy: 0.9175 - val_loss: 0.5044 - val_accuracy: 0.9412\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 1s 16us/sample - loss: 0.5762 - accuracy: 0.9207 - val_loss: 0.4713 - val_accuracy: 0.9436\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.5415 - accuracy: 0.9223 - val_loss: 0.4409 - val_accuracy: 0.9447\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 1s 18us/sample - loss: 0.5143 - accuracy: 0.9227 - val_loss: 0.4167 - val_accuracy: 0.9473\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 1s 16us/sample - loss: 0.4887 - accuracy: 0.9239 - val_loss: 0.3942 - val_accuracy: 0.9473\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.4671 - accuracy: 0.9264 - val_loss: 0.3742 - val_accuracy: 0.9489\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.4443 - accuracy: 0.9284 - val_loss: 0.3561 - val_accuracy: 0.9499\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.4281 - accuracy: 0.9299 - val_loss: 0.3406 - val_accuracy: 0.9512\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 1s 16us/sample - loss: 0.4105 - accuracy: 0.9317 - val_loss: 0.3292 - val_accuracy: 0.9522\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 1s 16us/sample - loss: 0.3985 - accuracy: 0.9313 - val_loss: 0.3157 - val_accuracy: 0.9540\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 1s 16us/sample - loss: 0.3843 - accuracy: 0.9332 - val_loss: 0.3041 - val_accuracy: 0.9546\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.3755 - accuracy: 0.9327 - val_loss: 0.2977 - val_accuracy: 0.9532\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.3657 - accuracy: 0.9344 - val_loss: 0.2856 - val_accuracy: 0.9566\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.3553 - accuracy: 0.9360 - val_loss: 0.2817 - val_accuracy: 0.9549\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 1s 16us/sample - loss: 0.3434 - accuracy: 0.9370 - val_loss: 0.2751 - val_accuracy: 0.9551\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.3385 - accuracy: 0.9368 - val_loss: 0.2667 - val_accuracy: 0.9574\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.3328 - accuracy: 0.9381 - val_loss: 0.2600 - val_accuracy: 0.9583\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.3266 - accuracy: 0.9398 - val_loss: 0.2558 - val_accuracy: 0.9587\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.3198 - accuracy: 0.9402 - val_loss: 0.2548 - val_accuracy: 0.9572\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.3141 - accuracy: 0.9406 - val_loss: 0.2473 - val_accuracy: 0.9582\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.3086 - accuracy: 0.9415 - val_loss: 0.2435 - val_accuracy: 0.9597\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.3038 - accuracy: 0.9430 - val_loss: 0.2414 - val_accuracy: 0.9599\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.2985 - accuracy: 0.9438 - val_loss: 0.2371 - val_accuracy: 0.9616\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.2981 - accuracy: 0.9433 - val_loss: 0.2336 - val_accuracy: 0.9613\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.2934 - accuracy: 0.9437 - val_loss: 0.2308 - val_accuracy: 0.9606\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.2894 - accuracy: 0.9453 - val_loss: 0.2259 - val_accuracy: 0.9622\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.2852 - accuracy: 0.9451 - val_loss: 0.2253 - val_accuracy: 0.9622\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 1s 18us/sample - loss: 0.2839 - accuracy: 0.9460 - val_loss: 0.2217 - val_accuracy: 0.9625\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.2806 - accuracy: 0.9465 - val_loss: 0.2206 - val_accuracy: 0.9632\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.2769 - accuracy: 0.9467 - val_loss: 0.2164 - val_accuracy: 0.9637\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.2726 - accuracy: 0.9482 - val_loss: 0.2153 - val_accuracy: 0.9636\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.2719 - accuracy: 0.9485 - val_loss: 0.2141 - val_accuracy: 0.9640\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.2683 - accuracy: 0.9491 - val_loss: 0.2138 - val_accuracy: 0.9638\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.2678 - accuracy: 0.9484 - val_loss: 0.2088 - val_accuracy: 0.9644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19022984a88>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 51us/sample - loss: 0.2080 - accuracy: 0.9628\n",
      "0.2080107888698578\n",
      "0.9628\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print(test_loss)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.6493987e-05, 4.7528636e-05, 4.0056676e-04, 7.3539105e-04,\n",
       "        2.3515262e-05, 2.0036303e-05, 3.6781494e-06, 9.9791437e-01,\n",
       "        1.8494517e-05, 7.4992259e-04]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[0].reshape((1,784)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(X_test[0].reshape((1,784)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.6493987e-05, 4.7528636e-05, 4.0056676e-04, 7.3539105e-04,\n",
       "        2.3515262e-05, 2.0036303e-05, 3.6781494e-06, 9.9791437e-01,\n",
       "        1.8494517e-05, 7.4992259e-04]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_test[0].reshape((1,784)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
